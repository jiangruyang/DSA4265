# üí≥ Credit Card Rewards Optimizer: Singapore Edition üá∏üá¨

A Singapore-focused application that uses Generative AI to analyze consumer spending patterns and provide multi-card synergy recommendations with strategic usage guidelines. The system uses an agentic architecture leveraging the Model Context Protocol (MCP) to power AI-driven chat for scenario planning and T&C clarifications.

## ‚ú® Features

- **Spending Analysis**: Analyze transaction data to create a comprehensive spending profile
- **Merchant Categorization**: Categorize merchant names into spending categories using a distilled model trained on ACRA business data
- **Card Recommendation**: Recommend optimal credit card combinations based on spending patterns and user preferences
- **Strategic Usage**: Provide specific advice on which card to use for which spending category
- **T&C Insights**: Answer natural language questions about card terms and conditions

## üå≥ Project Structure

```plaintext
project/
‚îú‚îÄ‚îÄ app.py                     # Launcher script for Streamlit app
‚îú‚îÄ‚îÄ src/                       # Main source code
‚îÇ   ‚îú‚îÄ‚îÄ agent/                 # Card optimizer agent implementation
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ agent.py           # Main agent implementation
‚îÇ   ‚îú‚îÄ‚îÄ card_processing/       # Card data processing modules
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ vector_db.py       # Vector database implementation
‚îÇ   ‚îú‚îÄ‚îÄ data_collection/       # Data collection utilities
‚îÇ   ‚îú‚îÄ‚îÄ model_context_protocol/  # MCP implementation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ client.py          # MCP client for server communication
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ card_data_server.py  # Card data access server
‚îÇ   ‚îú‚îÄ‚îÄ statement_processing/  # Statement analysis modules
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ merchant_categorizer.py  # Merchant categorization model
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ merchant_categorizer_trainer.py  # Training for categorizer
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pdf_statement_parser.py  # PDF parsing module
‚îÇ   ‚îî‚îÄ‚îÄ user_interface/        # Streamlit UI components
‚îÇ       ‚îú‚îÄ‚îÄ Welcome.py         # Main Streamlit entry point
‚îÇ       ‚îú‚îÄ‚îÄ components.py      # Reusable UI components
‚îÇ       ‚îú‚îÄ‚îÄ utils.py           # UI utility functions
‚îÇ       ‚îî‚îÄ‚îÄ pages/             # Additional app pages
‚îú‚îÄ‚îÄ models/                    # Trained models
‚îÇ   ‚îî‚îÄ‚îÄ merchant_categorizer/  # Merchant categorization models
‚îú‚îÄ‚îÄ data/                      # Data storage
‚îÇ   ‚îú‚îÄ‚îÄ card/                  # Card data
‚îÇ   ‚îú‚îÄ‚îÄ card_tcs/              # Card terms and conditions
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pdf/               # Original T&C PDFs
‚îÇ   ‚îú‚îÄ‚îÄ categorization/        # Categorization data
‚îÇ   ‚îú‚îÄ‚îÄ sample_statements/     # Sample card statements for testing
‚îÇ   ‚îî‚îÄ‚îÄ vector_db/             # Vector database storage
‚îú‚îÄ‚îÄ notebooks/                 # Jupyter notebooks for analysis
‚îú‚îÄ‚îÄ docs/                      # Documentation files
‚îú‚îÄ‚îÄ results/                   # Analysis results and outputs
‚îú‚îÄ‚îÄ logs/                      # Application logs
‚îî‚îÄ‚îÄ requirements.txt           # Python dependencies
```

## üìã Requirements

- python>=3.13

## üèóÔ∏è Setup Instructions

1. Create a virtual environment:

   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: .\venv\Scripts\Activate.ps1
   ```

2. Install dependancies:

   ```bash
   apt-get install build-essential libpoppler-cpp-dev pkg-config ocrmypdf
   ```

   or

   ```bash
   brew install gcc@11 pkg-config poppler ocrmypdf
   ```

   For Windows, you have to manually find these binaries and ensure they are discoverable. It is likely that these would be available on Windows package managers like `Winget` or `Chocolatey`, but I have not tested them yet.

3. Install requirements:

   ```bash
   pip install -r requirements.txt
   ```

4. Create a .env file by copying .env.example and filling in required values.

5. Start the MCP server:

   ```bash
   python -m src.model_context_protocol.card_data_server
   ```

6. (**In a new terminal window**) Run the Streamlit application:

   ```bash
   python app.py
   ```

For Docker, see [DOCKER.md](DOCKER.md).

## üßê Component Overview

### 1. Transaction Categorization

- `src/statement_processing/merchant_categorizer.py` - Model for categorizing merchant names
- `src/statement_processing/merchant_categorizer_trainer.py` - Training pipeline for categorizer model
- `src/statement_processing/pdf_statement_parser.py` - PDF statement parsing and data extraction

### 2. Card Embeddings & Semantic Search

- `src/card_processing/vector_db.py` - Vector database for card embeddings and T&C documents
- `src/model_context_protocol/card_data_server.py` - MCP tools for card data access including semantic search

### 3. Agent Reasoning

- `src/agent/agent.py` - Main agent implementation for card recommendations and scenario analysis

### 4. RAG Pipeline

- `src/card_processing/vector_db.py` - Vector database for T&C document storage
- `src/model_context_protocol/card_data_server.py` - Tools for T&C querying

### 5. UI & Application Flow

- `app.py` - Main application entry point
- `src/user_interface/Welcome.py` - Streamlit UI main page
- `src/user_interface/components.py` - Reusable UI components
- `src/user_interface/utils.py` - UI utility functions

## MCP Tool Architecture

The system implements core MCP tools through the `src/model_context_protocol/card_data_server.py`:

1. `get_available_cards()` - Returns a list of all available cards with basic metadata
2. `get_card_details(card_id)` - Returns complete card information in its original format
3. `query_tc(question, card_id)` - Natural language queries about card terms and conditions
4. `search_cards(query)` - Semantic search for cards matching natural language criteria
